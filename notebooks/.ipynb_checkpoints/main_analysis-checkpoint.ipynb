{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419f8a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# üß† Neural Spike Analysis: Rate vs Temporal Coding\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook analyzes neural spike data to determine whether information is encoded in **firing rates** or **temporal patterns**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from scipy import stats\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import our custom modules\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from spike_data_loader import SpikeDataLoader\\n\",\n",
    "    \"from spike_analyzer import SpikeAnalyzer\\n\",\n",
    "    \"from spike_visualizer import SpikeVisualizer\\n\",\n",
    "    \"from decoding_analysis import DecodingAnalysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ All modules imported successfully!\\\")\\n\",\n",
    "    \"print(\\\"üß† Ready for neural analysis!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize analysis modules\\n\",\n",
    "    \"loader = SpikeDataLoader()\\n\",\n",
    "    \"analyzer = SpikeAnalyzer()\\n\",\n",
    "    \"visualizer = SpikeVisualizer(style='dark')\\n\",\n",
    "    \"decoder = DecodingAnalysis()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üîß Analysis modules initialized!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìÇ Load Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"**IMPORTANT**: If you've generated data using the data generator, uncomment and use the first option. Otherwise, we'll generate synthetic data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# ===== OPTION 1: Load generated data files (RECOMMENDED) =====\\n\",\n",
    "    \"# Uncomment these lines if you've run the data generator:\\n\",\n",
    "    \"\\n\",\n",
    "    \"# spike_data = loader.load_spike_data('../data/neural_data_mixed_coding.npz')\\n\",\n",
    "    \"# spike_times = spike_data['spike_times']\\n\",\n",
    "    \"# unit_ids = spike_data['unit_ids']\\n\",\n",
    "    \"# event_times = spike_data['event_times']\\n\",\n",
    "    \"# event_labels = spike_data['event_labels']\\n\",\n",
    "    \"# print(\\\"‚úÖ Loaded data from file!\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ===== OPTION 2: Generate data on-the-fly =====\\n\",\n",
    "    \"# Use this if you haven't generated data files yet\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üìä Generating synthetic data...\\\")\\n\",\n",
    "    \"synthetic_data = loader.create_synthetic_data(\\n\",\n",
    "    \"    n_trials=80,\\n\",\n",
    "    \"    n_units=10,\\n\",\n",
    "    \"    duration=4.0,\\n\",\n",
    "    \"    stimulus_effect=2.0\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"spike_times = synthetic_data['spike_times']\\n\",\n",
    "    \"unit_ids = synthetic_data['unit_ids']\\n\",\n",
    "    \"event_times = synthetic_data['event_times']\\n\",\n",
    "    \"event_labels = synthetic_data['event_labels']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"‚úÖ Data ready:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ {len(np.unique(unit_ids))} units\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ {len(event_times)} trials\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ {len(spike_times)} total spikes\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create trial structure\\n\",\n",
    "    \"print(\\\"üîÑ Creating trial-aligned data...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"trials_data = loader.create_trials(\\n\",\n",
    "    \"    spike_times=spike_times,\\n\",\n",
    "    \"    unit_ids=unit_ids,\\n\",\n",
    "    \"    event_times=event_times,\\n\",\n",
    "    \"    event_labels=event_labels,\\n\",\n",
    "    \"    pre_time=1.0,\\n\",\n",
    "    \"    post_time=3.0\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"‚úÖ Created {len(trials_data)} trials\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show data summary\\n\",\n",
    "    \"summary = loader.get_data_summary(trials_data)\\n\",\n",
    "    \"print(\\\"\\\\nüìä Data Summary:\\\")\\n\",\n",
    "    \"for key, value in summary.items():\\n\",\n",
    "    \"    print(f\\\"   ‚Ä¢ {key}: {value}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîç Quality Control\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze unit quality\\n\",\n",
    "    \"print(\\\"üîç Quality control analysis...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"unit_stats = analyzer.calculate_unit_stats(trials_data)\\n\",\n",
    "    \"good_units = analyzer.filter_good_units(\\n\",\n",
    "    \"    unit_stats,\\n\",\n",
    "    \"    min_firing_rate=0.1,\\n\",\n",
    "    \"    max_refractory_violations=0.02,\\n\",\n",
    "    \"    min_total_spikes=50\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"‚úÖ {len(good_units)}/{len(unit_stats)} units passed QC\\\")\\n\",\n",
    "    \"print(f\\\"Good units: {good_units}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize quality\\n\",\n",
    "    \"fig = visualizer.plot_unit_quality(unit_stats, good_units)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìä Spike Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Pick a good unit for visualization\\n\",\n",
    "    \"if good_units:\\n\",\n",
    "    \"    example_unit = good_units[0]\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    example_unit = list(unit_stats.keys())[0]\\n\",\n",
    "    \"    print(\\\"‚ö†Ô∏è Using first available unit (didn't pass QC)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üìä Visualizing Unit {example_unit}...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Beautiful raster plot and PSTH\\n\",\n",
    "    \"fig = visualizer.plot_raster_psth(trials_data, example_unit)\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ISI analysis\\n\",\n",
    "    \"fig = visualizer.plot_isi_distribution(trials_data, example_unit)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìà Find Responsive Units\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test which units respond to stimulus\\n\",\n",
    "    \"print(\\\"üìà Testing for stimulus-responsive units...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"responsive_units = []\\n\",\n",
    "    \"response_stats = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for unit_id in good_units:\\n\",\n",
    "    \"    # Compare baseline vs stimulus periods\\n\",\n",
    "    \"    baseline_rates, stim_rates = analyzer.get_baseline_vs_stimulus_rates(\\n\",\n",
    "    \"        trials_data, unit_id,\\n\",\n",
    "    \"        baseline_window=(-1.0, 0.0),\\n\",\n",
    "    \"        stim_window=(0.0, 2.0)\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Statistical test\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        stat, p_value = stats.wilcoxon(baseline_rates, stim_rates, alternative='two-sided')\\n\",\n",
    "    \"    except:\\n\",\n",
    "    \"        p_value = 1.0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    response_stats[unit_id] = {\\n\",\n",
    "    \"        'baseline_rate': np.mean(baseline_rates),\\n\",\n",
    "    \"        'stimulus_rate': np.mean(stim_rates),\\n\",\n",
    "    \"        'p_value': p_value,\\n\",\n",
    "    \"        'responsive': p_value < 0.05\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if p_value < 0.05:\\n\",\n",
    "    \"        responsive_units.append(unit_id)\\n\",\n",
    "    \"        print(f\\\"   ‚úÖ Unit {unit_id}: responsive (p = {p_value:.4f})\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(f\\\"   ‚ùå Unit {unit_id}: not responsive (p = {p_value:.4f})\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìä {len(responsive_units)}/{len(good_units)} units are responsive\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize responses\\n\",\n",
    "    \"if response_stats:\\n\",\n",
    "    \"    fig = visualizer.plot_response_statistics(response_stats)\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üéØ MAIN ANALYSIS: Rate vs Temporal Coding\\n\",\n",
    "    \"\\n\",\n",
    "    \"This is the core analysis! We'll compare how well we can decode stimulus type using:\\n\",\n",
    "    \"- **Rate features**: Spike counts\\n\",\n",
    "    \"- **Temporal features**: Precise timing patterns\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Select units for decoding\\n\",\n",
    "    \"analysis_units = responsive_units if responsive_units else good_units[:5]\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not analysis_units:\\n\",\n",
    "    \"    analysis_units = list(unit_stats.keys())[:5]\\n\",\n",
    "    \"    print(\\\"‚ö†Ô∏è Using any available units\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üéØ Decoding with {len(analysis_units)} units: {analysis_units}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Extract features\\n\",\n",
    "    \"print(\\\"\\\\nüìä Extracting features...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Rate features (spike counts)\\n\",\n",
    "    \"rate_features = decoder.extract_rate_features(\\n\",\n",
    "    \"    trials_data, analysis_units, time_window=(0.0, 2.0)\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Temporal features (binned spike patterns)\\n\",\n",
    "    \"temporal_features = decoder.extract_temporal_features(\\n\",\n",
    "    \"    trials_data, analysis_units, time_window=(0.0, 2.0), bin_size=0.1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get trial labels\\n\",\n",
    "    \"labels = decoder.get_trial_labels(trials_data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"‚úÖ Rate features: {rate_features.shape}\\\")\\n\",\n",
    "    \"print(f\\\"‚úÖ Temporal features: {temporal_features.shape}\\\")\\n\",\n",
    "    \"print(f\\\"‚úÖ Labels: {np.unique(labels, return_counts=True)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare decoding performance\\n\",\n",
    "    \"print(\\\"üéØ Running decoding analysis...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"results = decoder.compare_decoding_performance(\\n\",\n",
    "    \"    rate_features=rate_features,\\n\",\n",
    "    \"    temporal_features=temporal_features,\\n\",\n",
    "    \"    labels=labels,\\n\",\n",
    "    \"    n_folds=5\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüéØ DECODING RESULTS:\\\")\\n\",\n",
    "    \"print(f\\\"   Rate accuracy:     {results['rate_accuracy']:.3f} ¬± {results['rate_std']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"   Temporal accuracy: {results['temporal_accuracy']:.3f} ¬± {results['temporal_std']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"   Shuffle control:   {results['shuffle_accuracy']:.3f} ¬± {results['shuffle_std']:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"   Temporal AUC:      {results['temporal_auc']:.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Statistical significance\\n\",\n",
    "    \"if results['p_value_rate_vs_temporal'] < 0.05:\\n\",\n",
    "    \"    significance = \\\"SIGNIFICANT\\\"\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    significance = \\\"not significant\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"print(f\\\"\\\\nüìä Rate vs Temporal: p = {results['p_value_rate_vs_temporal']:.4f} ({significance})\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize results\\n\",\n",
    "    \"fig = visualizer.plot_decoding_results(results)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üî¨ Advanced Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Cross-correlation between units\\n\",\n",
    "    \"if len(analysis_units) >= 2:\\n\",\n",
    "    \"    print(f\\\"üîó Cross-correlation: Unit {analysis_units[0]} vs {analysis_units[1]}\\\")\\n\",\n",
    "    \"    fig = visualizer.plot_cross_correlation(trials_data, analysis_units[0], analysis_units[1])\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Individual unit performance\\n\",\n",
    "    \"print(\\\"\\\\nüîç Individual unit decoding:\\\")\\n\",\n",
    "    \"individual_results = decoder.analyze_individual_units(trials_data, analysis_units[:3])\\n\",\n",
    "    \"\\n\",\n",
    "    \"for unit_id, result in individual_results.items():\\n\",\n",
    "    \"    improvement = result['improvement']\\n\",\n",
    "    \"    print(f\\\"   Unit {unit_id}: Rate={result['rate_accuracy']:.3f}, Temporal={result['temporal_accuracy']:.3f}, Œî={improvement:+.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üìã Final Results & Conclusions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Generate comprehensive report\\n\",\n",
    "    \"report = decoder.create_decoding_report(results, analysis_units)\\n\",\n",
    "    \"print(report)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Final interpretation\\n\",\n",
    "    \"rate_acc = results['rate_accuracy']\\n\",\n",
    "    \"temp_acc = results['temporal_accuracy']\\n\",\n",
    "    \"improvement = temp_acc - rate_acc\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"üéØ FINAL CONCLUSIONS\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìä Performance Summary:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Rate-based decoding: {rate_acc:.1%}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Temporal decoding: {temp_acc:.1%}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Improvement: {improvement:+.1%}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüß† Coding Strategy:\\\")\\n\",\n",
    "    \"if improvement > 0.05 and results['p_value_rate_vs_temporal'] < 0.05:\\n\",\n",
    "    \"    print(f\\\"   üéØ TEMPORAL CODING DETECTED!\\\")\\n\",\n",
    "    \"    print(f\\\"   üí° Neurons encode information in precise spike timing\\\")\\n\",\n",
    "    \"    print(f\\\"   üî¨ Focus on synchrony and temporal dynamics\\\")\\n\",\n",
    "    \"elif improvement < -0.05 and results['p_value_rate_vs_temporal'] < 0.05:\\n\",\n",
    "    \"    print(f\\\"   üìä RATE CODING DETECTED!\\\")\\n\",\n",
    "    \"    print(f\\\"   üí° Neurons encode information in firing rates\\\")\\n\",\n",
    "    \"    print(f\\\"   üî¨ Spike counts are sufficient\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(f\\\"   ü§î MIXED/UNCLEAR CODING\\\")\\n\",\n",
    "    \"    print(f\\\"   üí° Both rate and timing may contribute\\\")\\n\",\n",
    "    \"    print(f\\\"   üî¨ Consider hybrid approaches\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nüìà Dataset Quality:\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Good units: {len(good_units)}/{len(unit_stats)}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Responsive units: {len(responsive_units)}\\\")\\n\",\n",
    "    \"print(f\\\"   ‚Ä¢ Total trials: {len(trials_data)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if temp_acc > 0.7:\\n\",\n",
    "    \"    print(f\\\"\\\\n‚ú® Excellent decoding performance!\\\")\\n\",\n",
    "    \"elif temp_acc > 0.6:\\n\",\n",
    "    \"    print(f\\\"\\\\nüëç Good decoding performance\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(f\\\"\\\\nüí° Consider improving data quality or increasing trials\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüß† Analysis Complete! üéâ\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## üöÄ Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Try different datasets**: If you generated multiple data files, load different ones to see how results change\\n\",\n",
    "    \"2. **Adjust parameters**: Change time windows, bin sizes, etc.\\n\",\n",
    "    \"3. **Add more units**: Include more units in the analysis\\n\",\n",
    "    \"4. **Extend analysis**: Add population-level metrics, more sophisticated decoders\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Congratulations on completing your neural coding analysis! üß†‚ú®**\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
